{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.kitti_api.auxiliary.laserscan import SemLaserScan\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import json\n",
    "import albumentations as A\n",
    "import cv2\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permute(image):\n",
    "    image = torch.Tensor(image)\n",
    "    image = image.permute(2,0,1).numpy()\n",
    "    return image\n",
    "\n",
    "def mapping(labels,config):\n",
    "    \n",
    "    labels[labels == 252] = 10\n",
    "    labels[labels == 253] = 31\n",
    "    labels[labels == 254] = 30\n",
    "    labels[labels == 255] = 32\n",
    "    labels[labels == 256] = 16\n",
    "    labels[labels == 257] = 13\n",
    "    labels[labels == 258] = 18\n",
    "    labels[labels == 259] = 20\n",
    "    \n",
    "    classes = [ -1,\n",
    "                10,\n",
    "                11,\n",
    "                15,\n",
    "                18,\n",
    "                20,\n",
    "                30,\n",
    "                31,\n",
    "                32,\n",
    "                40,\n",
    "                48,\n",
    "                49,\n",
    "                50,\n",
    "                70,\n",
    "                71,\n",
    "                72,\n",
    "                80,\n",
    "                81\n",
    "                ]\n",
    "    for unique_value in np.unique(labels):\n",
    "        if unique_value not in classes:\n",
    "                labels[labels == unique_value] = -1\n",
    "    \n",
    "    \n",
    "    for i,label in enumerate(classes):\n",
    "        labels[labels == label] = i\n",
    "        #print(f'Matching: {label}:{i}')\n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matching: -1:0\n",
    "Matching: 10:1\n",
    "Matching: 11:2\n",
    "Matching: 15:3\n",
    "Matching: 18:4\n",
    "Matching: 20:5\n",
    "Matching: 30:6\n",
    "Matching: 31:7\n",
    "Matching: 32:8\n",
    "Matching: 40:9\n",
    "Matching: 48:10\n",
    "Matching: 49:11\n",
    "Matching: 50:12\n",
    "Matching: 70:13\n",
    "Matching: 71:14\n",
    "Matching: 72:15\n",
    "Matching: 80:16\n",
    "Matching: 81:17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permute(image):\n",
    "    image = torch.Tensor(image)\n",
    "    image = image.permute(2,0,1).numpy()\n",
    "    return image\n",
    "\n",
    "def mapping(labels,config):\n",
    "    \n",
    "    labels[labels == 252] = 10\n",
    "    labels[labels == 253] = 31\n",
    "    labels[labels == 254] = 30\n",
    "    labels[labels == 255] = 32\n",
    "    labels[labels == 256] = 16\n",
    "    labels[labels == 257] = 13\n",
    "    labels[labels == 258] = 18\n",
    "    labels[labels == 259] = 20\n",
    "    \n",
    "    for i,label in enumerate(list(config['labels'].keys())[:-8]):\n",
    "        labels[labels == label] = i\n",
    "    \n",
    "    labels_temp = labels.copy()\n",
    "    \n",
    "    labels[:] = 0\n",
    "    \n",
    "    labels[labels_temp == 12] = 1\n",
    "    labels[labels_temp == 13] = 1 #parking = road\n",
    "    \n",
    "    labels[labels_temp == 2] = 2\n",
    "    labels[labels_temp == 4] = 2\n",
    "    labels[labels_temp == 7] = 2\n",
    "    labels[labels_temp == 8] = 2 #car = bus = truck = other-vehicle\n",
    "    \n",
    "#     labels[labels_temp == 3] = 3\n",
    "#     labels[labels_temp == 5] = 3 #bycikle = motocycle\n",
    "    \n",
    "    labels[labels_temp == 14] = 3 #sidewalk\n",
    "        \n",
    "#     labels[labels_temp == 10] = 5\n",
    "#     labels[labels_temp == 11] = 5 \n",
    "#     labels[labels_temp == 9] = 5 #byciklist = motocyclist = person\n",
    "    \n",
    "    labels[labels_temp == 20] = 4 #vegetation\n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmitrii/anaconda3/envs/dmitrii_thesis/lib/python3.7/site-packages/ipykernel_launcher.py:1: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "CONFIG = yaml.load(open(\"./utils/kitti_api/config/semantic-kitti.yaml\"))\n",
    "    \n",
    "DATA_PATH = './data/kitti_dataset/raw_data/data_odometry_velodyne/dataset/sequences/'\n",
    "OUT_PATH = './data/kitti_dataset/processed_data/'\n",
    "TABLE_PATH = './data/split_tables/kitti/'\n",
    "\n",
    "os.makedirs(TABLE_PATH,exist_ok=True)\n",
    "\n",
    "#check all records\n",
    "seq_list = [DATA_PATH+i for i in os.listdir(DATA_PATH) if i.find('.')==-1]\n",
    "\n",
    "\n",
    "laserscan_class = SemLaserScan(nclasses=len(list(CONFIG['labels'].keys())),project=True,sem_color_dict=CONFIG['color_map'],H=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'unlabeled',\n",
       " 1: 'outlier',\n",
       " 10: 'car',\n",
       " 11: 'bicycle',\n",
       " 13: 'bus',\n",
       " 15: 'motorcycle',\n",
       " 16: 'on-rails',\n",
       " 18: 'truck',\n",
       " 20: 'other-vehicle',\n",
       " 30: 'person',\n",
       " 31: 'bicyclist',\n",
       " 32: 'motorcyclist',\n",
       " 40: 'road',\n",
       " 44: 'parking',\n",
       " 48: 'sidewalk',\n",
       " 49: 'other-ground',\n",
       " 50: 'building',\n",
       " 51: 'fence',\n",
       " 52: 'other-structure',\n",
       " 60: 'lane-marking',\n",
       " 70: 'vegetation',\n",
       " 71: 'trunk',\n",
       " 72: 'terrain',\n",
       " 80: 'pole',\n",
       " 81: 'traffic-sign',\n",
       " 99: 'other-object',\n",
       " 252: 'moving-car',\n",
       " 253: 'moving-bicyclist',\n",
       " 254: 'moving-person',\n",
       " 255: 'moving-motorcyclist',\n",
       " 256: 'moving-on-rails',\n",
       " 257: 'moving-bus',\n",
       " 258: 'moving-truck',\n",
       " 259: 'moving-other-vehicle'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONFIG['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matching: 0: 0\n",
    "Matching: 1: 1\n",
    "Matching: 10: 2\n",
    "Matching: 11: 3\n",
    "Matching: 13: 4\n",
    "Matching: 15: 5\n",
    "Matching: 16: 6\n",
    "Matching: 18: 7\n",
    "Matching: 20: 8\n",
    "Matching: 30: 9\n",
    "Matching: 31: 10\n",
    "Matching: 32: 11\n",
    "Matching: 40: 12\n",
    "Matching: 44: 13\n",
    "Matching: 48: 14\n",
    "Matching: 49: 15\n",
    "Matching: 50: 16\n",
    "Matching: 51: 17\n",
    "Matching: 52: 18\n",
    "Matching: 60: 19\n",
    "Matching: 70: 20\n",
    "Matching: 71: 21\n",
    "Matching: 72: 22\n",
    "Matching: 80: 23\n",
    "Matching: 81: 24\n",
    "Matching: 99: 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 408/408 [00:26<00:00, 15.26it/s]\n",
      "100%|██████████| 111/111 [00:07<00:00, 15.53it/s]\n",
      "100%|██████████| 81/81 [00:05<00:00, 15.44it/s]\n",
      "100%|██████████| 277/277 [00:19<00:00, 14.26it/s]\n",
      "100%|██████████| 111/111 [00:07<00:00, 15.16it/s]\n",
      "100%|██████████| 111/111 [00:06<00:00, 16.47it/s]\n",
      "100%|██████████| 121/121 [00:09<00:00, 13.39it/s]\n",
      "100%|██████████| 160/160 [00:10<00:00, 15.26it/s]\n",
      "100%|██████████| 467/467 [00:31<00:00, 15.04it/s]\n",
      "100%|██████████| 455/455 [00:30<00:00, 14.88it/s]\n",
      "100%|██████████| 28/28 [00:01<00:00, 15.22it/s]\n"
     ]
    }
   ],
   "source": [
    "for seq in seq_list:\n",
    "    \n",
    "    scans = [i[:-4] for i in os.listdir(seq+'/velodyne/') if i.find('.bin')!=-1]\n",
    "    scans = scans[0::10]\n",
    "    \n",
    "    for scan in tqdm(scans):\n",
    "        laserscan_class.open_scan(seq+'/velodyne/'+scan + '.bin')\n",
    "        laserscan_class.open_label(seq+'/labels/'+scan + '.label')\n",
    "        \n",
    "        #get image\n",
    "        image = laserscan_class.proj_xyz\n",
    "        depth = laserscan_class.proj_range\n",
    "        remission = laserscan_class.proj_remission\n",
    "        \n",
    "        #stack image\n",
    "        image = permute(image)\n",
    "        depth = np.expand_dims(depth,axis=0)\n",
    "        remission = np.expand_dims(remission,axis=0)\n",
    "        image = np.append(image,depth,axis=0)\n",
    "        image = np.append(image,remission,axis=0)\n",
    "        \n",
    "        #get labels\n",
    "        labels = laserscan_class.proj_sem_label\n",
    "        labels = mapping(labels,config=CONFIG)\n",
    "        labels = np.expand_dims(labels,axis=0)\n",
    "        \n",
    "        #get mask\n",
    "        mask = laserscan_class.proj_mask\n",
    "        mask = np.expand_dims(mask,axis=0)\n",
    "        \n",
    "        os.makedirs(OUT_PATH+seq.split('/')[-1],exist_ok=True)\n",
    "        \n",
    "        #save data\n",
    "        np.save(OUT_PATH+seq.split('/')[-1]+f'/{scan}_scan.npy',image)\n",
    "        np.save(OUT_PATH+seq.split('/')[-1]+f'/{scan}_label.npy',labels)\n",
    "        np.save(OUT_PATH+seq.split('/')[-1]+f'/{scan}_mask.npy',mask)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare split tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seq = [\n",
    "    './data/kitti_dataset/processed_data/08',\n",
    "     './data/kitti_dataset/processed_data/02',\n",
    "]\n",
    "\n",
    "train_UB = [\n",
    "     './data/kitti_dataset/processed_data/06',\n",
    " './data/kitti_dataset/processed_data/03',\n",
    "    \n",
    "         './data/kitti_dataset/processed_data/00',\n",
    "     './data/kitti_dataset/processed_data/05',\n",
    "    './data/kitti_dataset/processed_data/09',\n",
    "     './data/kitti_dataset/processed_data/10',\n",
    "]\n",
    "\n",
    "val_UB = [\n",
    " './data/kitti_dataset/processed_data/07',\n",
    " './data/kitti_dataset/processed_data/01',\n",
    " './data/kitti_dataset/processed_data/04'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_data(seq_list: list):\n",
    "    seq_arr = []\n",
    "    scans = []\n",
    "    for seq in seq_list:\n",
    "        scans += [seq+'/'+i for i in os.listdir(seq) if i.find('scan')!=-1]\n",
    "        seq_arr += [seq]*len([seq+'/'+i for i in os.listdir(seq) if i.find('scan')!=-1])\n",
    "\n",
    "    scans = np.array(scans)\n",
    "    seq_arr = np.array(seq_arr)\n",
    "    return scans,seq_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create test\n",
    "\n",
    "records_test,_ = upload_data(test_seq)\n",
    "\n",
    "\n",
    "#create test\n",
    "split = {\n",
    "        'test': records_test.tolist(),\n",
    "    }\n",
    "\n",
    "with open(f'{TABLE_PATH}test_split_table.json', 'w') as outfile:\n",
    "        json.dump(split, outfile)\n",
    "        \n",
    "print(f'Seq in test set: {len(test_seq)}')\n",
    "print(f'Images in test set: {records_test.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create UB\n",
    "\n",
    "train_records,_ = upload_data(train_UB)\n",
    "val_records,_ = upload_data(val_UB)\n",
    "\n",
    "split = {\n",
    "        'train': train_records.tolist(),\n",
    "        'val': val_records.tolist(),\n",
    "        }\n",
    "with open(f'{TABLE_PATH}UB_split_table.json', 'w') as outfile:\n",
    "            json.dump(split, outfile)\n",
    "\n",
    "print(f'Seq in UB train set: {len(train_UB)}')\n",
    "print(f'Images in UB train set: {train_records.shape[0]}')\n",
    "print(f'Seq in UB val set: {len(val_UB)}')\n",
    "print(f'Images in UB val set: {val_records.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset train: ./data/kitti_dataset/processed_data/06, N samples: 2\n",
      "Dataset train: ./data/kitti_dataset/processed_data/03, N samples: 2\n",
      "Dataset train: ./data/kitti_dataset/processed_data/00, N samples: 9\n",
      "Dataset train: ./data/kitti_dataset/processed_data/05, N samples: 6\n",
      "Dataset train: ./data/kitti_dataset/processed_data/09, N samples: 3\n",
      "Dataset train: ./data/kitti_dataset/processed_data/10, N samples: 2\n",
      "Dataset val: ./data/kitti_dataset/processed_data/07, N samples: 2\n",
      "Dataset val: ./data/kitti_dataset/processed_data/01, N samples: 2\n",
      "Dataset val: ./data/kitti_dataset/processed_data/04, N samples: 1\n",
      "\n",
      "\n",
      "Part data: 2%\n",
      "Seq in UB train set: 6\n",
      "Images in UB train set: 24\n",
      "Seq in UB val set: 3\n",
      "Images in UB val set: 5\n",
      "Dataset train: ./data/kitti_dataset/processed_data/06, N samples: 4\n",
      "Dataset train: ./data/kitti_dataset/processed_data/03, N samples: 3\n",
      "Dataset train: ./data/kitti_dataset/processed_data/00, N samples: 18\n",
      "Dataset train: ./data/kitti_dataset/processed_data/05, N samples: 11\n",
      "Dataset train: ./data/kitti_dataset/processed_data/09, N samples: 6\n",
      "Dataset train: ./data/kitti_dataset/processed_data/10, N samples: 5\n",
      "Dataset val: ./data/kitti_dataset/processed_data/07, N samples: 4\n",
      "Dataset val: ./data/kitti_dataset/processed_data/01, N samples: 4\n",
      "Dataset val: ./data/kitti_dataset/processed_data/04, N samples: 1\n",
      "\n",
      "\n",
      "Part data: 4%\n",
      "Seq in UB train set: 6\n",
      "Images in UB train set: 47\n",
      "Seq in UB val set: 3\n",
      "Images in UB val set: 9\n",
      "Dataset train: ./data/kitti_dataset/processed_data/06, N samples: 9\n",
      "Dataset train: ./data/kitti_dataset/processed_data/03, N samples: 6\n",
      "Dataset train: ./data/kitti_dataset/processed_data/00, N samples: 36\n",
      "Dataset train: ./data/kitti_dataset/processed_data/05, N samples: 22\n",
      "Dataset train: ./data/kitti_dataset/processed_data/09, N samples: 13\n",
      "Dataset train: ./data/kitti_dataset/processed_data/10, N samples: 10\n",
      "Dataset val: ./data/kitti_dataset/processed_data/07, N samples: 9\n",
      "Dataset val: ./data/kitti_dataset/processed_data/01, N samples: 9\n",
      "Dataset val: ./data/kitti_dataset/processed_data/04, N samples: 2\n",
      "\n",
      "\n",
      "Part data: 8%\n",
      "Seq in UB train set: 6\n",
      "Images in UB train set: 96\n",
      "Seq in UB val set: 3\n",
      "Images in UB val set: 20\n"
     ]
    }
   ],
   "source": [
    "#create train and validation\n",
    "\n",
    "part_data = [2,4,8] # % of each record, but validate only on 1% of each \n",
    "\n",
    "for part in part_data:\n",
    "    \n",
    "    train = []\n",
    "    val = []\n",
    "    for seq in train_UB:\n",
    "        train_records,_ = upload_data([seq])\n",
    "        np.random.permutation(train_records)\n",
    "        train_records = train_records[:int(np.round(train_records.shape[0]*(part/100)))]\n",
    "        print(f'Dataset train: {seq}, N samples: {train_records.shape[0]}')\n",
    "        train += train_records.tolist()\n",
    "    \n",
    "    for seq in val_UB:\n",
    "        val_records,_ = upload_data([seq])\n",
    "        np.random.permutation(val_records)\n",
    "        val_records = val_records[:int(np.round(val_records.shape[0]*(part/100)))]\n",
    "        print(f'Dataset val: {seq}, N samples: {val_records.shape[0]}')\n",
    "        val += val_records.tolist()\n",
    "    \n",
    "    print('\\n')\n",
    "    \n",
    "    \n",
    "    split = {\n",
    "            'train': train,\n",
    "            'val': val,\n",
    "            'pretrain': records.tolist()\n",
    "        }\n",
    "    with open(f'{TABLE_PATH}{part}_split_table.json', 'w') as outfile:\n",
    "            json.dump(split, outfile)\n",
    "    \n",
    "    print(f'Part data: {part}%')\n",
    "    print(f'Seq in UB train set: {len(train_UB)}')\n",
    "    print(f'Images in UB train set: {len(train)}')\n",
    "    print(f'Seq in UB val set: {len(val_UB)}')\n",
    "    print(f'Images in UB val set: {len(val)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review augs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = 100\n",
    "augs = A.Compose(\n",
    "                [\n",
    "                    A.HorizontalFlip(p=prob),\n",
    "                    A.Rotate(limit=5, p=prob),\n",
    "\n",
    "                ]\n",
    "            )\n",
    "temp = np.transpose(image.astype(np.float32), (1, 2, 0))\n",
    "augmented = augs(image=temp)\n",
    "temp = np.transpose(temp.astype(np.float32), (2, 0, 1))\n",
    "image_aug = augmented['image']\n",
    "image_aug = np.transpose(image_aug.astype(np.float32), (2, 0, 1))\n",
    "\n",
    "plt.figure(figsize=(30,10))\n",
    "plt.imshow(temp[0],'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,10))\n",
    "plt.imshow(image_aug[0],'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = labels.copy()\n",
    "temp[temp != 12] = 1\n",
    "temp[temp == 12] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,10))\n",
    "plt.imshow(image[0])\n",
    "\n",
    "plt.figure(figsize=(30,10))\n",
    "plt.imshow(image[1])\n",
    "\n",
    "plt.figure(figsize=(30,10))\n",
    "plt.imshow(image[2])\n",
    "\n",
    "plt.figure(figsize=(30,10))\n",
    "plt.imshow(image[3])\n",
    "\n",
    "plt.figure(figsize=(30,10))\n",
    "plt.imshow(image[4])\n",
    "\n",
    "plt.figure(figsize=(30,10))\n",
    "plt.imshow(labels[0])\n",
    "\n",
    "plt.figure(figsize=(30,10))\n",
    "plt.imshow(mask[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
